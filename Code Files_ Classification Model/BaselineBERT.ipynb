{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11065446,"sourceType":"datasetVersion","datasetId":6895146}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[]}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"markdown","source":["Group 5\n","\n","Julia Aptekar, DePaul University, japtekar@depaul.edu\n","\n","John Leniart, DePaul University, jleniart@depaul.edu\n","\n","Arham Mehdi, DePaul University kmehdi@depaul.edu\n","\n","Natalie Olechno, DePaul University, nolechno@depaul.edu\n","\n"],"metadata":{"id":"Xe2PuB4dL7RU"}},{"source":["# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n","# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n","import kagglehub\n","kagglehub.login()\n"],"metadata":{"id":"F8fmpVVQiFpc"},"cell_type":"code","outputs":[],"execution_count":null},{"source":["# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n","# THEN FEEL FREE TO DELETE THIS CELL.\n","# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n","# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n","# NOTEBOOK.\n","\n","nat7574_combined_data_path = kagglehub.dataset_download('nat7574/combined-data')\n","\n","print('Data source import complete.')\n"],"metadata":{"id":"79lV-s5WiFpd"},"cell_type":"code","outputs":[],"execution_count":null},{"cell_type":"code","source":["#from google.colab import drive\n","#drive.mount('/content/drive')\n","\n","#file_1 = '/content/drive/MyDrive/Data Science Capstone/Original Data/Combined Data.xlsx'\n","#data = pd.read_excel(file_1)"],"metadata":{"id":"geNWbBgaKYrW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import re\n","import random\n","import time\n","import datetime\n","from collections import Counter\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split, RandomSampler, WeightedRandomSampler, Subset, SequentialSampler\n","\n","from transformers import BertTokenizer, BertModel, BertForSequenceClassification\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","\n","from sklearn.metrics import f1_score, precision_score, recall_score, classification_report\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","\n","#basic BERT\n","class BasicBertClassifier(nn.Module):\n","    def __init__(self, num_outcome_labels, dropout_rate=0.3):\n","        super(BasicBertClassifier, self).__init__()\n","        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n","        self.dropout = nn.Dropout(dropout_rate)\n","        self.classifier = nn.Linear(self.bert.config.hidden_size, num_outcome_labels)\n","\n","    def forward(self, input_ids, attention_mask):\n","        bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask).pooler_output\n","        bert_output = self.dropout(bert_output)\n","        logits = self.classifier(bert_output)\n","        return logits\n","\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","input_file='/kaggle/input/combined-data/Combined Data.xlsx'\n","print(f\"Loading data from {input_file}\")\n","data = pd.read_excel(input_file)\n","\n","data.dropna(inplace=True)\n","data['outcomeid'] = data['outcomeid'].astype(int)\n","data['programdescription'] = data['programdescription'].apply(lambda x: re.sub(r\"[^A-Za-z0-9 :.,'-]+\", \"\", x))\n","\n","outcome_encoder = LabelEncoder()\n","data['encoded_outcome_labels'] = outcome_encoder.fit_transform(data['outcomeid'])\n","num_outcome_labels = len(outcome_encoder.classes_)\n","print(f\"Number of outcome labels: {num_outcome_labels}\")\n","\n","label_counts = Counter(data['encoded_outcome_labels'])\n","min_class_size = min(label_counts.values())\n","print(f\"Smallest class has {min_class_size} samples\")\n","\n","stratify_option = data['encoded_outcome_labels'] if min_class_size > 1 else None\n","\n","sentences = data['programdescription'].tolist()\n","outcome_labels = torch.tensor(data['encoded_outcome_labels'].tolist())\n","\n","tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n","\n","def tokenize_data(sentences, max_length=240):\n","    input_ids = []\n","    attention_masks = []\n","    for sent in sentences:\n","        encoded_dict = tokenizer.encode_plus(\n","            sent,\n","            add_special_tokens=True,\n","            max_length=max_length,\n","            pad_to_max_length=True,\n","            return_attention_mask=True,\n","            return_tensors='pt'\n","        )\n","        input_ids.append(encoded_dict['input_ids'])\n","        attention_masks.append(encoded_dict['attention_mask'])\n","    return torch.cat(input_ids), torch.cat(attention_masks)\n","\n","input_ids, attention_masks = tokenize_data(sentences)\n","\n","dataset = TensorDataset(input_ids, attention_masks, outcome_labels)\n","\n","train_idx, val_idx = train_test_split(\n","    range(len(dataset)),\n","    test_size=0.2,\n","    random_state=42,\n","    stratify=stratify_option\n",")\n","\n","train_dataset = TensorDataset(\n","    input_ids[train_idx],\n","    attention_masks[train_idx],\n","    outcome_labels[train_idx]\n",")\n","\n","val_dataset = TensorDataset(\n","    input_ids[val_idx],\n","    attention_masks[val_idx],\n","    outcome_labels[val_idx]\n",")\n","\n","print(f\"Training samples: {len(train_dataset)}\")\n","print(f\"Validation samples: {len(val_dataset)}\")\n","\n","batch_size = 16\n","train_dataloader = DataLoader(\n","    train_dataset,\n","    batch_size=batch_size\n",")\n","\n","validation_dataloader = DataLoader(\n","    val_dataset,\n","    sampler=SequentialSampler(val_dataset),\n","    batch_size=batch_size\n",")\n","\n","model = BasicBertClassifier(num_outcome_labels)\n","model.to(device)\n","\n","outcome_loss_fn = nn.CrossEntropyLoss()\n","\n","optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n","\n","def format_time(elapsed):\n","    elapsed_rounded = int(round((elapsed)))\n","    return str(datetime.timedelta(seconds=elapsed_rounded))\n","\n","seed_val = 42\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","print('Training...')\n","t0 = time.time()\n","total_train_loss = 0\n","model.train()\n","\n","outcome_correct = 0\n","total_examples = 0\n","\n","for step, batch in enumerate(train_dataloader):\n","    if step % 40 == 0 and step != 0:\n","        elapsed = format_time(time.time() - t0)\n","        print(f'  Batch {step:>5,} of {len(train_dataloader):>5,}. Elapsed: {elapsed}.')\n","\n","    input_ids, attention_mask, outcome_labels = [b.to(device) for b in batch]\n","    optimizer.zero_grad()\n","    logits = model(input_ids, attention_mask)\n","    loss = outcome_loss_fn(logits, outcome_labels)\n","    loss.backward()\n","    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","    optimizer.step()\n","\n","    total_train_loss += loss.item()\n","    total_examples += input_ids.size(0)\n","\n","    _, outcome_preds = torch.max(logits, dim=1)\n","    outcome_correct += (outcome_preds == outcome_labels).sum().item()\n","\n","avg_train_loss = total_train_loss / len(train_dataloader)\n","outcome_accuracy = outcome_correct / total_examples\n","\n","training_time = format_time(time.time() - t0)\n","print(f\"  Average training loss: {avg_train_loss:.4f}\")\n","print(f\"  Outcome Accuracy: {outcome_accuracy:.4f}\")\n","print(f\"  Training took: {training_time}\")\n","\n","print(\"\\nRunning Validation...\")\n","t0 = time.time()\n","model.eval()\n","\n","total_eval_loss = 0\n","val_outcome_correct = 0\n","val_total = 0\n","\n","all_outcome_preds = []\n","all_outcome_labels = []\n","\n","with torch.no_grad():\n","    for batch in validation_dataloader:\n","        input_ids, attention_mask, outcome_labels = [b.to(device) for b in batch]\n","\n","        logits = model(input_ids, attention_mask)\n","\n","        loss = outcome_loss_fn(logits, outcome_labels)\n","        total_eval_loss += loss.item()\n","        val_total += input_ids.size(0)\n","\n","        _, outcome_preds = torch.max(logits, dim=1)\n","\n","        all_outcome_preds.extend(outcome_preds.cpu().numpy())\n","        all_outcome_labels.extend(outcome_labels.cpu().numpy())\n","\n","        val_outcome_correct += (outcome_preds == outcome_labels).sum().item()\n","\n","avg_val_loss = total_eval_loss / len(validation_dataloader)\n","val_outcome_accuracy = val_outcome_correct / val_total\n","outcome_precision = precision_score(all_outcome_labels, all_outcome_preds, average='macro')\n","outcome_recall = recall_score(all_outcome_labels, all_outcome_preds, average='macro')\n","outcome_f1 = f1_score(all_outcome_labels, all_outcome_preds, average='macro')\n","\n","validation_time = format_time(time.time() - t0)\n","\n","print(f\"  Validation Loss: {avg_val_loss:.4f}\")\n","print(f\"  Outcome Accuracy: {val_outcome_accuracy:.4f}\")\n","print(f\"  Outcome Precision: {outcome_precision:.4f}\")\n","print(f\"  Outcome Recall: {outcome_recall:.4f}\")\n","print(f\"  Outcome F1 Score: {outcome_f1:.4f}\")\n","print(f\"  Validation took: {validation_time}\")\n","\n","model_path = '/kaggle/working/basic_bert_model.pt'\n","torch.save({\n","    'model': model,\n","    'outcome_encoder': outcome_encoder,\n","    'model_class': BasicBertClassifier,\n","    'f1_score': outcome_f1,\n","    'precision': outcome_precision,\n","    'recall': outcome_recall\n","}, model_path)\n","\n","print(f\"\\nModel saved to {model_path}\")\n","print(f\"Final outcome F1 score: {outcome_f1:.4f}\")"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T17:42:06.661451Z","iopub.execute_input":"2025-03-19T17:42:06.661652Z","iopub.status.idle":"2025-03-19T17:49:15.218824Z","shell.execute_reply.started":"2025-03-19T17:42:06.661632Z","shell.execute_reply":"2025-03-19T17:49:15.218003Z"},"id":"9BbbWgbAiFpd","outputId":"2426b312-3eaa-4e2c-aabf-953cae922d98","colab":{"referenced_widgets":["ba508791d4c8475d913ead7677413979","a1e31715f3114f30885fba9c93eafa9d","1765baa37a924a1f9fb08021005d3c34","df293a7a898b422bbc16354cffb931ff","911f32903bc843c3a030921b1ccfc732"]}},"outputs":[{"name":"stdout","text":"Using device: cuda\nLoading data from /kaggle/input/combined-data/Combined Data.xlsx\nNumber of outcome labels: 289\nSmallest class has 1 samples\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba508791d4c8475d913ead7677413979"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1e31715f3114f30885fba9c93eafa9d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1765baa37a924a1f9fb08021005d3c34"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df293a7a898b422bbc16354cffb931ff"}},"metadata":{}},{"name":"stderr","text":"Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2673: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Training samples: 8680\nValidation samples: 2171\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"911f32903bc843c3a030921b1ccfc732"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Training...\n  Batch    40 of   543. Elapsed: 0:00:24.\n  Batch    80 of   543. Elapsed: 0:00:46.\n  Batch   120 of   543. Elapsed: 0:01:09.\n  Batch   160 of   543. Elapsed: 0:01:32.\n  Batch   200 of   543. Elapsed: 0:01:57.\n  Batch   240 of   543. Elapsed: 0:02:22.\n  Batch   280 of   543. Elapsed: 0:02:47.\n  Batch   320 of   543. Elapsed: 0:03:11.\n  Batch   360 of   543. Elapsed: 0:03:36.\n  Batch   400 of   543. Elapsed: 0:04:01.\n  Batch   440 of   543. Elapsed: 0:04:25.\n  Batch   480 of   543. Elapsed: 0:04:50.\n  Batch   520 of   543. Elapsed: 0:05:15.\n  Average training loss: 4.9729\n  Outcome Accuracy: 0.1116\n  Training took: 0:05:29\n\nRunning Validation...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"  Validation Loss: 4.1819\n  Outcome Accuracy: 0.2358\n  Outcome Precision: 0.0909\n  Outcome Recall: 0.1406\n  Outcome F1 Score: 0.0900\n  Validation took: 0:00:27\n\nModel saved to /kaggle/working/basic_bert_model.pt\nFinal outcome F1 score: 0.0900\n","output_type":"stream"}],"execution_count":null}]}